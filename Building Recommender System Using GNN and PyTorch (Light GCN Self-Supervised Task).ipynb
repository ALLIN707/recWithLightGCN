{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51add8c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f2afec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "import copy\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5bbd8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3efc5d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "# https://grouplens.org/datasets/movielens/\n",
    "# \"Small: 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. Last updated 9/2018\"\n",
    "#url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "#extract_zip(download_url(url, '.'), '.')\n",
    "\n",
    "movie_path = './ml-latest-small/movies.csv'\n",
    "rating_path = './ml-latest-small/ratings.csv'\n",
    "user_path = './ml-latest-small/users.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e424873",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "9724\n",
      "610\n"
     ]
    },
    {
     "data": {
      "text/plain": "              userId        movieId         rating     timestamp\ncount  100836.000000  100836.000000  100836.000000  1.008360e+05\nmean      326.127564   19435.295718       3.501557  1.205946e+09\nstd       182.618491   35530.987199       1.042529  2.162610e+08\nmin         1.000000       1.000000       0.500000  8.281246e+08\n25%       177.000000    1199.000000       3.000000  1.019124e+09\n50%       325.000000    2991.000000       3.500000  1.186087e+09\n75%       477.000000    8122.000000       4.000000  1.435994e+09\nmax       610.000000  193609.000000       5.000000  1.537799e+09",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100836.000000</td>\n      <td>100836.000000</td>\n      <td>100836.000000</td>\n      <td>1.008360e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>326.127564</td>\n      <td>19435.295718</td>\n      <td>3.501557</td>\n      <td>1.205946e+09</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>182.618491</td>\n      <td>35530.987199</td>\n      <td>1.042529</td>\n      <td>2.162610e+08</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>8.281246e+08</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>177.000000</td>\n      <td>1199.000000</td>\n      <td>3.000000</td>\n      <td>1.019124e+09</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>325.000000</td>\n      <td>2991.000000</td>\n      <td>3.500000</td>\n      <td>1.186087e+09</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>477.000000</td>\n      <td>8122.000000</td>\n      <td>4.000000</td>\n      <td>1.435994e+09</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>610.000000</td>\n      <td>193609.000000</td>\n      <td>5.000000</td>\n      <td>1.537799e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.read_csv(rating_path)\n",
    "\n",
    "print(rating_df.head())\n",
    "\n",
    "print(len(rating_df['movieId'].unique()))\n",
    "print(len(rating_df['userId'].unique()))\n",
    "\n",
    "rating_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe203e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# perform encoding preprocessing to ensure that user_id and item_id are both \n",
    "# in the range of [0, unique_count] so it won't cause out of bound issue when indexing embeddings\n",
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "\n",
    "rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n",
    "rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28f158cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609\n",
      "9723\n"
     ]
    }
   ],
   "source": [
    "print(rating_df.userId.max())\n",
    "print(rating_df.movieId.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11d7fe8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4.0    26818\n3.0    20047\n5.0    13211\n3.5    13136\n4.5     8551\n2.0     7551\n2.5     5550\n1.0     2811\n1.5     1791\n0.5     1370\nName: rating, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d88002",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load edges between users and movies\n",
    "def load_edge_csv(df, \n",
    "                  src_index_col, \n",
    "                  dst_index_col, \n",
    "                  link_index_col, \n",
    "                  rating_threshold=3):\n",
    "    \"\"\"Loads csv containing edges between users and items\n",
    "\n",
    "    Args:\n",
    "        src_index_col (str): column name of users\n",
    "        dst_index_col (str): column name of items\n",
    "        link_index_col (str): column name of user item interaction\n",
    "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        list of list: edge_index -- 2 by N matrix containing the node ids of N user-item edges\n",
    "        N here is the number of interactions\n",
    "    \"\"\"\n",
    "    \n",
    "    edge_index = None\n",
    "    \n",
    "    # Constructing COO format edge_index from input rating events\n",
    "    \n",
    "    # get user_ids from rating events in the order of occurance\n",
    "    src = [user_id for user_id in  df['userId']]    \n",
    "    # get movie_id from rating events in the order of occurance\n",
    "    dst = [(movie_id) for movie_id in df['movieId']]\n",
    "\n",
    "    # apply rating threshold\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
    "\n",
    "    edge_index = [[], []]\n",
    "    for i in range(edge_attr.shape[0]):\n",
    "        if edge_attr[i]:\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b833faa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 x 48580\n"
     ]
    }
   ],
   "source": [
    "edge_index = load_edge_csv(\n",
    "    rating_df,\n",
    "    src_index_col='userId',\n",
    "    dst_index_col='movieId',\n",
    "    link_index_col='rating',\n",
    "    rating_threshold=3.5, \n",
    ")\n",
    "\n",
    "print(f\"{len(edge_index)} x {len(edge_index[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc93f95",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
      "        [   0,    2,    5,  ..., 9443, 9444, 9445]])\n",
      "torch.Size([2, 48580])\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensor\n",
    "# We use LongTensor here because the .propagate() method in the model needs either LongTensor or SparseTensor\n",
    "edge_index = torch.LongTensor(edge_index) \n",
    "print(edge_index)\n",
    "print(edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe67af24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Note: this is the total num_users and num_movies before we apply the rating_threshold\n",
    "num_users = len(rating_df['userId'].unique())\n",
    "num_movies = len(rating_df['movieId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f894f13a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_interactions = edge_index.shape[1]\n",
    "\n",
    "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
    "all_indices = [i for i in range(num_interactions)]\n",
    "\n",
    "train_indices, test_indices = train_test_split(all_indices, \n",
    "                                               test_size=0.2, \n",
    "                                               random_state=1)\n",
    "\n",
    "val_indices, test_indices = train_test_split(test_indices, \n",
    "                                             test_size=0.5, \n",
    "                                             random_state=1)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96b6e105",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users 610, num_movies 9724, num_interactions 48580\n",
      "train_edge_index tensor([[ 605,  110,  442,  ...,   65,  161,  427],\n",
      "        [1110, 9619, 1283,  ..., 4640,  443,  827]])\n",
      "10334\n",
      "torch.Size([609])\n",
      "torch.Size([5676])\n"
     ]
    }
   ],
   "source": [
    "print(f\"num_users {num_users}, num_movies {num_movies}, num_interactions {num_interactions}\")\n",
    "print(f\"train_edge_index {train_edge_index}\")\n",
    "print((num_users + num_movies))\n",
    "print(torch.unique(train_edge_index[0]).size())\n",
    "print(torch.unique(train_edge_index[1]).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fa1a8c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index):\n",
    "    R = torch.zeros((num_users, num_movies))\n",
    "    for i in range(len(input_edge_index[0])):\n",
    "        row_idx = input_edge_index[0][i]\n",
    "        col_idx = input_edge_index[1][i]\n",
    "        R[row_idx][col_idx] = 1\n",
    "\n",
    "    R_transpose = torch.transpose(R, 0, 1)\n",
    "    adj_mat = torch.zeros((num_users + num_movies , num_users + num_movies))\n",
    "    adj_mat[: num_users, num_users :] = R.clone()\n",
    "    adj_mat[num_users :, : num_users] = R_transpose.clone()\n",
    "    adj_mat_coo = adj_mat.to_sparse_coo()\n",
    "    adj_mat_coo = adj_mat_coo.indices()\n",
    "    return adj_mat_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07043bf3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index):\n",
    "    sparse_input_edge_index = SparseTensor(row=input_edge_index[0], \n",
    "                                           col=input_edge_index[1], \n",
    "                                           sparse_sizes=((num_users + num_movies), num_users + num_movies))\n",
    "    adj_mat = sparse_input_edge_index.to_dense()\n",
    "    interact_mat = adj_mat[: num_users, num_users :]\n",
    "    r_mat_edge_index = interact_mat.to_sparse_coo().indices()\n",
    "    return r_mat_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b20c90e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert from r_mat (interaction matrix) edge index to adjescency matrix's edge index \n",
    "# so we can feed it to model\n",
    "train_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index)\n",
    "val_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index)\n",
    "test_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "913fd3ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     0,     0,  ..., 10326, 10327, 10333],\n",
      "        [  610,   612,   653,  ...,   183,   183,   330]])\n",
      "torch.Size([2, 77728])\n",
      "tensor([[    0,     0,     0,  ..., 10226, 10236, 10240],\n",
      "        [  615,   794,  2010,  ...,   317,   204,   413]])\n",
      "torch.Size([2, 9716])\n",
      "tensor([[    0,     0,     0,  ..., 10301, 10302, 10329],\n",
      "        [  811,  1086,  1095,  ...,   585,   585,   183]])\n",
      "torch.Size([2, 9716])\n"
     ]
    }
   ],
   "source": [
    "print(train_edge_index)\n",
    "print(train_edge_index.size())\n",
    "print(val_edge_index)\n",
    "print(val_edge_index.size())\n",
    "print(test_edge_index)\n",
    "print(test_edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1a04338",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# helper function for training and compute BPR loss\n",
    "# since this is a self-supervised learning, we are relying on the graph structure itself and \n",
    "# we don't have label other than the graph structure so we need to the folloing function\n",
    "# which random samples a mini-batch of positive and negative samples\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): minibatch size\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        tuple: user indices, positive item indices, negative item indices\n",
    "    \"\"\"\n",
    "    # structured_negative_sampling is a pyG library\n",
    "    # Samples a negative edge :obj:`(i,k)` for every positive edge\n",
    "    # :obj:`(i,j)` in the graph given by :attr:`edge_index`, and returns it as a\n",
    "    # tuple of the form :obj:`(i,j,k)`.\n",
    "    #\n",
    "    #         >>> edge_index = torch.as_tensor([[0, 0, 1, 2],\n",
    "    #         ...                               [0, 1, 2, 3]])\n",
    "    #         >>> structured_negative_sampling(edge_index)\n",
    "    #         (tensor([0, 0, 1, 2]), tensor([0, 1, 2, 3]), tensor([2, 3, 0, 2]))\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    \n",
    "    # 3 x edge_index_len\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    \n",
    "    # here is whhen we actually perform the batch sampe\n",
    "    # Return a k sized list of population elements chosen with replacement.\n",
    "    indices = random.choices([i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "    \n",
    "    batch = edges[:, indices]\n",
    "    \n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    return user_indices, pos_item_indices, neg_item_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3688310d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Implementing LightGCN\n",
    "\n",
    "## Light Graph Convolution\n",
    "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
    "\\end{equation}\n",
    "\n",
    "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
    "\n",
    "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
    "\n",
    "$e_u^{(k)}$ : k-th layer user embedding\n",
    "\n",
    "$e_i^{(k)}$ : k-th layer item embedding\n",
    "\n",
    "\n",
    "\n",
    "## Layer Combination and Model Prediction\n",
    "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
    "\\end{equation}\n",
    "\n",
    "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
    "\n",
    "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}_{ui} = e_u^Te_i\n",
    "\\end{equation}\n",
    "\n",
    "## Matrix Form\n",
    "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. \n",
    "\n",
    "\\begin{equation}\n",
    "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
    "\\end{equation}\n",
    "\n",
    "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
    "\n",
    "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e8cbb67",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# defines LightGCN model \n",
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, \n",
    "                 num_items, \n",
    "                 embedding_dim=64, # define the embding vector length for each node\n",
    "                 K=3, \n",
    "                 add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.K = K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        # define user and item embedding for direct look up. \n",
    "        # embedding dimension: num_user/num_item x embedding_dim\n",
    "        \n",
    "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        \n",
    "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "\n",
    "        # \"Fills the input Tensor with values drawn from the normal distribution\"\n",
    "        # according to LightGCN paper, this gives better performance\n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index: Tensor):\n",
    "        \"\"\"Forward propagation of LightGCN Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "            \\tilde_A = D^(-1/2) * A * D^(-1/2)    according to LightGCN paper\n",
    "        \n",
    "            this is essentially a metrix operation way to get 1/ (sqrt(n_neighbors_i) * sqrt(n_neighbors_j))\n",
    "\n",
    "        \n",
    "            if your original edge_index look like\n",
    "            tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
    "                    [   0,    2,    5,  ..., 9444, 9445, 9485]])\n",
    "                    \n",
    "                    torch.Size([2, 99466])\n",
    "                    \n",
    "            then this will output: \n",
    "                (\n",
    "                 tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
    "                         [   0,    2,    5,  ..., 9444, 9445, 9485]]), \n",
    "                 tensor([0.0047, 0.0096, 0.0068,  ..., 0.0592, 0.0459, 0.1325])\n",
    "                 )\n",
    "                 \n",
    "              where edge_index_norm[0] is just the original edge_index\n",
    "              \n",
    "              and edge_index_norm[1] is the symmetrically normalization term. \n",
    "              \n",
    "            under the hood it's basically doing\n",
    "                def compute_gcn_norm(edge_index, emb):\n",
    "                    emb = emb.weight\n",
    "                    from_, to_ = edge_index\n",
    "                    deg = degree(to_, emb.size(0), dtype=emb.dtype)\n",
    "                    deg_inv_sqrt = deg.pow(-0.5)\n",
    "                    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "                    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
    "\n",
    "                    return norm\n",
    "                 \n",
    "                \n",
    "        \"\"\"\n",
    "        edge_index_norm = gcn_norm(edge_index=edge_index, \n",
    "                                   add_self_loops=self.add_self_loops)\n",
    "\n",
    "        # concat the user_emb and item_emb as the layer0 embing matrix\n",
    "        # size will be (n_users + n_items) x emb_vector_len.   e.g: 10334 x 64\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "\n",
    "        embs = [emb_0] # save the layer0 emb to the embs list\n",
    "        \n",
    "        # emb_k is the emb that we are actually going to push it through the graph layers\n",
    "        # as described in lightGCN paper formula 7\n",
    "        emb_k = emb_0 \n",
    "\n",
    "        # push the embedding of all users and items through the Graph Model K times.\n",
    "        # K here is the number of layers\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index=edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n",
    "            embs.append(emb_k)\n",
    "            \n",
    "            \n",
    "        # this is doing the formula8 in LightGCN paper  \n",
    "            \n",
    "        # the stacked embs is a list of embedding matrix at each layer\n",
    "        #    it's of shape n_nodes x (n_layers + 1) x emb_vector_len. \n",
    "        #        e.g: torch.Size([10334, 4, 64])\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        \n",
    "        # From LightGCn paper: \"In our experiments, we find that setting α_k uniformly as 1/(K + 1)\n",
    "        #    leads to good performance in general.\"\n",
    "        emb_final = torch.mean(embs, dim=1) # E^K\n",
    "\n",
    "\n",
    "        # splits into e_u^K and e_i^K\n",
    "        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items]) \n",
    "\n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        # here using .weight to get the tensor weights from n.Embedding\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j is of shape:  edge_index_len x emb_vector_len\n",
    "        #    e.g: torch.Size([77728, 64]\n",
    "        #\n",
    "        # x_j is basically the embedding of all the neighbors based on the src_list in coo edge index\n",
    "        # \n",
    "        # elementwise multiply by the symmetrically norm. So it's essentiall what formula 7 in LightGCN\n",
    "        # paper does but here we are using edge_index rather than Adj Matrix\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "layers = 3    \n",
    "model = LightGCN(num_users=num_users, \n",
    "                 num_items=num_movies, \n",
    "                 K=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea1884a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffad4fa8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loss Function\n",
    "\n",
    "\n",
    "\n",
    "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
    "\n",
    "\\begin{equation}\n",
    "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
    "\\end{equation}\n",
    "\n",
    "$\\hat{y}_{u}$: predicted score of a positive sample\n",
    "\n",
    "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
    "\n",
    "$\\lambda$: hyperparameter which controls the L2 regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cee24091",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb_final, \n",
    "             users_emb_0, \n",
    "             pos_items_emb_final, \n",
    "             pos_items_emb_0, \n",
    "             neg_items_emb_final, \n",
    "             neg_items_emb_0, \n",
    "             lambda_val):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        users_emb_0 (torch.Tensor): e_u_0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
    "        lambda_val (float): lambda value for regularization loss term\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
    "\n",
    "\n",
    "    bpr_loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores))\n",
    "    \n",
    "    loss = bpr_loss + reg_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c5c914",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We evalaluate our model using the following metrics\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Recall} = \\frac{TP}{TP + FP}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Precision} = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "\n",
    "Recall@k and Precision@k is just applying only the topK recommended items and then for the overall\n",
    "Recall@k and Precision@k, it's just averaged by the number of users\n",
    "\n",
    "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
    "\\end{equation}\n",
    "\n",
    "p: a particular rank position\n",
    "\n",
    "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
    "\n",
    "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
    "\\end{equation}\n",
    "\n",
    "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
    "\n",
    "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
    "\\end{equation}\n",
    "\n",
    "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a6dc66e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"\n",
    "    Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges \n",
    "\n",
    "    Returns:\n",
    "        dict: user -> list of positive items for each \n",
    "    \"\"\"\n",
    "    \n",
    "    # key: user_id, val: item_id list\n",
    "    user_pos_items = {}\n",
    "    \n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        \n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        \n",
    "        user_pos_items[user].append(item)\n",
    "        \n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ace2aa34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# computes recall@K and precision@K\n",
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"Computers recall @ k and precision @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list[list[long]]): list of lists of item_ids. Cntaining highly rated items of each user. \n",
    "                            In other words, this is the list of true_relevant_items for each user\n",
    "                            \n",
    "        r (list[list[boolean]]): list of lists indicating whether each top k item recommended to each user\n",
    "                            is a top k ground truth (true relevant) item or not\n",
    "                            \n",
    "        k (int): determines the top k items to compute precision and recall on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of correctly predicted items per user\n",
    "    # -1 here means I want to sum at the inner most dimension\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  \n",
    "    \n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i]) for i in range(len(groundTruth))])\n",
    "    \n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa475ca5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# computes NDCG@K\n",
    "def NDCGatK_r(groundTruth, r, k):\n",
    "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (int): determines the top k items to compute ndcg on\n",
    "\n",
    "    Returns:\n",
    "        float: ndcg @ k\n",
    "    \"\"\"\n",
    "    assert len(r) == len(groundTruth)\n",
    "\n",
    "    test_matrix = torch.zeros((len(r), k))\n",
    "\n",
    "    for i, items in enumerate(groundTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0.\n",
    "    return torch.mean(ndcg).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe2d3e12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "def get_metrics(model, \n",
    "                input_edge_index, # adj_mat based edge index\n",
    "                input_exclude_edge_indices, # adj_mat based exclude edge index\n",
    "                k):\n",
    "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        \n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        \n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        \n",
    "        k (int): determines the top k items to compute metrics on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    # get the embedding tensor at layer 0 after training\n",
    "    user_embedding = model.users_emb.weight\n",
    "    item_embedding = model.items_emb.weight\n",
    "    \n",
    "\n",
    "    # convert adj_mat based edge index to r_mat based edge index so we have have \n",
    "    # the first list being user_ids and second list being item_ids for the edge index \n",
    "    edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
    "\n",
    "    # This is to exclude the edges we have seen before in our predicted interaction matrix (r_mat_rating)\n",
    "    # E.g: for validation set, we want want to exclude all the edges in training set\n",
    "    exclude_edge_indices = [convert_adj_mat_edge_index_to_r_mat_edge_index(exclude_edge_index) \\\n",
    "                                      for exclude_edge_index in input_exclude_edge_indices]\n",
    "\n",
    "     \n",
    "\n",
    "    # Generate predicted interaction matrix (r_mat_rating)    \n",
    "    # (num_users x 64) dot_product (num_item x 64).T \n",
    "    r_mat_rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "    \n",
    "    # shape: num_users x num_item\n",
    "    rating = r_mat_rating\n",
    "   \n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        # gets all the positive items for each user from the edge index\n",
    "        # it's a dict: user -> positive item list\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        \n",
    "        # get coordinates of all edges to exclude\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            # [user] * len(item) can give us [user1, user1, user1...] with len of len(item)\n",
    "            # this makes easier to do the masking below\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "   \n",
    "        # set the excluded entry in the rat_mat_rating matrix to a very small number\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10) \n",
    "\n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    # dict of user -> pos_item list\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "\n",
    "    # convert test user pos items dictionary into a list of lists\n",
    "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "\n",
    "    # r here is \"pred_relevant_items ∩ actually_relevant_items\" list for each user\n",
    "    r = []\n",
    "    for user in users:\n",
    "        user_true_relevant_item = test_user_pos_items[user.item()]\n",
    "        # list of Booleans to store whether or not a given item in the top_K_items for a given user \n",
    "        # is also present in user_true_relevant_item.\n",
    "        # this is later on used to compute n_rel_and_rec_k\n",
    "        label = list(map(lambda x: x in user_true_relevant_item, top_K_items[user]))\n",
    "        r.append(label)\n",
    "        \n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b69b4158",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# wrapper function to evaluate model\n",
    "def evaluation(model, \n",
    "               edge_index, # adj_mat based edge index\n",
    "               exclude_edge_indices,  # adj_mat based exclude edge index\n",
    "               k, \n",
    "               lambda_val\n",
    "              ):\n",
    "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "        lambda_val (float): determines lambda for bpr loss\n",
    "\n",
    "    Returns:\n",
    "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    # get embeddings\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(edge_index)\n",
    "    \n",
    "    r_mat_edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(edge_index)\n",
    "    \n",
    "    edges = structured_negative_sampling(r_mat_edge_index, contains_neg_self_loops=False)\n",
    "    \n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    \n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    \n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    \n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "    loss = bpr_loss(users_emb_final, \n",
    "                    users_emb_0, \n",
    "                    pos_items_emb_final, \n",
    "                    pos_items_emb_0,\n",
    "                    neg_items_emb_final, \n",
    "                    neg_items_emb_0, \n",
    "                    lambda_val).item()\n",
    "\n",
    "\n",
    "    recall, precision, ndcg = get_metrics(model, \n",
    "                                          edge_index, \n",
    "                                          exclude_edge_indices, \n",
    "                                          k)\n",
    "\n",
    "    return loss, recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af8b0cc8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "316ba67b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training\n",
    "\n",
    "Your test set performance should be in line with the following (*K=20*):\n",
    "\n",
    "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4cee1b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define contants\n",
    "ITERATIONS = 10000\n",
    "EPOCHS = 10\n",
    "# ITERATIONS = 500\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6\n",
    "# LAMBDA = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d3b2d75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "371bdb47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_embs_for_bpr(model, input_edge_index):\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(input_edge_index)\n",
    "    \n",
    "\n",
    "    edge_index_to_use = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
    "    \n",
    "    # mini batching for eval and calculate loss \n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(BATCH_SIZE, edge_index_to_use)\n",
    "    \n",
    "    # This is to push tensor to device so if we are using GPU\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    \n",
    " \n",
    "    # we need layer0 embeddings and the final embeddings (computed from 0...K layer) for BPR loss computing\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
    "   \n",
    "    return users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcbf4944",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b7f792e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc6a001a6e904afcb3841c8a0b31f02e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/10000] train_loss: -0.693, val_loss: -0.69916, val_recall@20: 0.00054, val_precision@20: 0.00054, val_ndcg@20: 0.00064\n",
      "[Iteration 200/10000] train_loss: -6.75075, val_loss: -5.25332, val_recall@20: 0.0607, val_precision@20: 0.02107, val_ndcg@20: 0.04355\n",
      "[Iteration 400/10000] train_loss: -29.43986, val_loss: -21.38258, val_recall@20: 0.09201, val_precision@20: 0.02803, val_ndcg@20: 0.0594\n",
      "[Iteration 600/10000] train_loss: -63.71206, val_loss: -45.10998, val_recall@20: 0.10462, val_precision@20: 0.03318, val_ndcg@20: 0.07016\n",
      "[Iteration 800/10000] train_loss: -100.81306, val_loss: -74.67655, val_recall@20: 0.11861, val_precision@20: 0.0359, val_ndcg@20: 0.07766\n",
      "[Iteration 1000/10000] train_loss: -148.72067, val_loss: -108.24267, val_recall@20: 0.12832, val_precision@20: 0.03933, val_ndcg@20: 0.08395\n",
      "[Iteration 1200/10000] train_loss: -198.07884, val_loss: -144.18065, val_recall@20: 0.12957, val_precision@20: 0.03888, val_ndcg@20: 0.08722\n",
      "[Iteration 1400/10000] train_loss: -245.53116, val_loss: -182.58287, val_recall@20: 0.13708, val_precision@20: 0.04033, val_ndcg@20: 0.09159\n",
      "[Iteration 1600/10000] train_loss: -308.9382, val_loss: -224.37242, val_recall@20: 0.13399, val_precision@20: 0.04087, val_ndcg@20: 0.0907\n",
      "[Iteration 1800/10000] train_loss: -356.12509, val_loss: -264.46695, val_recall@20: 0.13476, val_precision@20: 0.04213, val_ndcg@20: 0.09215\n",
      "[Iteration 2000/10000] train_loss: -423.38535, val_loss: -305.44455, val_recall@20: 0.13688, val_precision@20: 0.04213, val_ndcg@20: 0.09271\n",
      "[Iteration 2200/10000] train_loss: -467.86386, val_loss: -349.66553, val_recall@20: 0.13415, val_precision@20: 0.0415, val_ndcg@20: 0.09277\n",
      "[Iteration 2400/10000] train_loss: -549.48029, val_loss: -385.14114, val_recall@20: 0.13824, val_precision@20: 0.04213, val_ndcg@20: 0.09453\n",
      "[Iteration 2600/10000] train_loss: -582.95496, val_loss: -428.59558, val_recall@20: 0.13621, val_precision@20: 0.04195, val_ndcg@20: 0.09474\n",
      "[Iteration 2800/10000] train_loss: -644.23413, val_loss: -466.40799, val_recall@20: 0.14114, val_precision@20: 0.04295, val_ndcg@20: 0.09868\n",
      "[Iteration 3000/10000] train_loss: -699.3233, val_loss: -500.3071, val_recall@20: 0.1405, val_precision@20: 0.04277, val_ndcg@20: 0.09831\n",
      "[Iteration 3200/10000] train_loss: -741.70764, val_loss: -540.65991, val_recall@20: 0.14065, val_precision@20: 0.04331, val_ndcg@20: 0.09838\n",
      "[Iteration 3400/10000] train_loss: -793.87097, val_loss: -576.36169, val_recall@20: 0.1434, val_precision@20: 0.04358, val_ndcg@20: 0.09974\n",
      "[Iteration 3600/10000] train_loss: -842.84521, val_loss: -613.92993, val_recall@20: 0.14344, val_precision@20: 0.0434, val_ndcg@20: 0.09997\n",
      "[Iteration 3800/10000] train_loss: -873.72906, val_loss: -647.64764, val_recall@20: 0.14104, val_precision@20: 0.04313, val_ndcg@20: 0.09942\n",
      "[Iteration 4000/10000] train_loss: -976.52325, val_loss: -678.08484, val_recall@20: 0.14248, val_precision@20: 0.04376, val_ndcg@20: 0.10016\n",
      "[Iteration 4200/10000] train_loss: -996.375, val_loss: -713.08441, val_recall@20: 0.14562, val_precision@20: 0.04403, val_ndcg@20: 0.1013\n",
      "[Iteration 4400/10000] train_loss: -991.15387, val_loss: -737.19562, val_recall@20: 0.1435, val_precision@20: 0.04367, val_ndcg@20: 0.10145\n",
      "[Iteration 4600/10000] train_loss: -1050.80933, val_loss: -764.83228, val_recall@20: 0.14183, val_precision@20: 0.04358, val_ndcg@20: 0.09981\n",
      "[Iteration 4800/10000] train_loss: -1086.76941, val_loss: -801.1228, val_recall@20: 0.1422, val_precision@20: 0.04376, val_ndcg@20: 0.1007\n",
      "[Iteration 5000/10000] train_loss: -1112.67444, val_loss: -825.92938, val_recall@20: 0.14282, val_precision@20: 0.04358, val_ndcg@20: 0.10056\n",
      "[Iteration 5200/10000] train_loss: -1163.19946, val_loss: -856.35059, val_recall@20: 0.14319, val_precision@20: 0.04412, val_ndcg@20: 0.10092\n",
      "[Iteration 5400/10000] train_loss: -1221.38342, val_loss: -876.47308, val_recall@20: 0.14042, val_precision@20: 0.04349, val_ndcg@20: 0.10005\n",
      "[Iteration 5600/10000] train_loss: -1178.22852, val_loss: -891.03693, val_recall@20: 0.14205, val_precision@20: 0.04385, val_ndcg@20: 0.10045\n",
      "[Iteration 5800/10000] train_loss: -1214.7605, val_loss: -914.39874, val_recall@20: 0.14202, val_precision@20: 0.04394, val_ndcg@20: 0.1009\n",
      "[Iteration 6000/10000] train_loss: -1374.7832, val_loss: -944.27924, val_recall@20: 0.142, val_precision@20: 0.04403, val_ndcg@20: 0.10105\n",
      "[Iteration 6200/10000] train_loss: -1270.11914, val_loss: -959.63434, val_recall@20: 0.14252, val_precision@20: 0.04412, val_ndcg@20: 0.10139\n",
      "[Iteration 6400/10000] train_loss: -1328.74146, val_loss: -988.43323, val_recall@20: 0.14291, val_precision@20: 0.04421, val_ndcg@20: 0.10148\n",
      "[Iteration 6600/10000] train_loss: -1408.1803, val_loss: -1005.65448, val_recall@20: 0.14221, val_precision@20: 0.04394, val_ndcg@20: 0.10124\n",
      "[Iteration 6800/10000] train_loss: -1379.71594, val_loss: -1021.66168, val_recall@20: 0.14212, val_precision@20: 0.04394, val_ndcg@20: 0.10138\n",
      "[Iteration 7000/10000] train_loss: -1437.74805, val_loss: -1031.86658, val_recall@20: 0.1428, val_precision@20: 0.04412, val_ndcg@20: 0.10163\n",
      "[Iteration 7200/10000] train_loss: -1406.15833, val_loss: -1047.27722, val_recall@20: 0.14301, val_precision@20: 0.04421, val_ndcg@20: 0.10166\n",
      "[Iteration 7400/10000] train_loss: -1461.43494, val_loss: -1068.91455, val_recall@20: 0.14326, val_precision@20: 0.04439, val_ndcg@20: 0.10187\n",
      "[Iteration 7600/10000] train_loss: -1481.95105, val_loss: -1076.24915, val_recall@20: 0.14283, val_precision@20: 0.04394, val_ndcg@20: 0.10126\n",
      "[Iteration 7800/10000] train_loss: -1510.5321, val_loss: -1088.32849, val_recall@20: 0.14314, val_precision@20: 0.0443, val_ndcg@20: 0.10154\n",
      "[Iteration 8000/10000] train_loss: -1538.28906, val_loss: -1100.67664, val_recall@20: 0.14314, val_precision@20: 0.0443, val_ndcg@20: 0.10159\n",
      "[Iteration 8200/10000] train_loss: -1493.59094, val_loss: -1127.43701, val_recall@20: 0.14291, val_precision@20: 0.04412, val_ndcg@20: 0.10145\n",
      "[Iteration 8400/10000] train_loss: -1629.11877, val_loss: -1141.9115, val_recall@20: 0.14306, val_precision@20: 0.04412, val_ndcg@20: 0.10151\n",
      "[Iteration 8600/10000] train_loss: -1578.63989, val_loss: -1156.95337, val_recall@20: 0.14217, val_precision@20: 0.04403, val_ndcg@20: 0.10131\n",
      "[Iteration 8800/10000] train_loss: -1600.70691, val_loss: -1156.875, val_recall@20: 0.14115, val_precision@20: 0.04367, val_ndcg@20: 0.1009\n",
      "[Iteration 9000/10000] train_loss: -1531.60669, val_loss: -1161.49707, val_recall@20: 0.14165, val_precision@20: 0.04394, val_ndcg@20: 0.10115\n",
      "[Iteration 9200/10000] train_loss: -1630.82043, val_loss: -1170.38916, val_recall@20: 0.14225, val_precision@20: 0.04403, val_ndcg@20: 0.10141\n",
      "[Iteration 9400/10000] train_loss: -1644.76428, val_loss: -1192.81079, val_recall@20: 0.14299, val_precision@20: 0.04403, val_ndcg@20: 0.1015\n",
      "[Iteration 9600/10000] train_loss: -1709.98315, val_loss: -1202.62207, val_recall@20: 0.14282, val_precision@20: 0.04394, val_ndcg@20: 0.1014\n",
      "[Iteration 9800/10000] train_loss: -1699.1593, val_loss: -1218.44885, val_recall@20: 0.14281, val_precision@20: 0.04385, val_ndcg@20: 0.10133\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_recall_at_ks = []\n",
    "\n",
    "for iter in tqdm(range(ITERATIONS)):\n",
    "    # forward propagation  \n",
    "    users_emb_final, users_emb_0,  pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0 \\\n",
    "                = get_embs_for_bpr(model, train_edge_index)\n",
    "    \n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, \n",
    "                          users_emb_0, \n",
    "                          pos_items_emb_final,\n",
    "                          pos_items_emb_0, \n",
    "                          neg_items_emb_final, \n",
    "                          neg_items_emb_0, \n",
    "                          LAMBDA)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # validation set\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_loss, recall, precision, ndcg = evaluation(model, \n",
    "                                                           val_edge_index, \n",
    "                                                           [train_edge_index], \n",
    "                                                           K, \n",
    "                                                           LAMBDA\n",
    "                                                          )\n",
    "\n",
    "            print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "\n",
    "            train_losses.append(train_loss.item())\n",
    "            val_losses.append(val_loss)\n",
    "            val_recall_at_ks.append(round(recall, 5))\n",
    "        model.train()\n",
    "\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "423573ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dabdd722",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e32fd3b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
    "plt.plot(iters, train_losses, label='train')\n",
    "plt.plot(iters, val_losses, label='validation')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training and validation loss curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "203b99c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f2 = plt.figure()\n",
    "plt.plot(iters, val_recall_at_ks, label='recall_at_k')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('recall_at_k')\n",
    "plt.title('recall_at_k curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9c96a3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_loss: -1217.25842, test_recall@20: 0.12561, test_precision@20: 0.04321, test_ndcg@20: 0.09756\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "model.eval()\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "\n",
    "test_loss, test_recall, test_precision, test_ndcg = evaluation(model, \n",
    "                                                               test_edge_index, \n",
    "                                                               [train_edge_index, val_edge_index], \n",
    "                                                               K, \n",
    "                                                               LAMBDA\n",
    "                                                              )\n",
    "\n",
    "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb7489fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}